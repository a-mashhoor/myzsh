# ===== Penetration Testing =====

function pentest-report()
{
  local report_file="report_$(date +%Y-%m-%d).md"
  echo "# Penetration Test Report - $(date)" > "$report_file"
  echo "## Target: $1" >> "$report_file"
  echo "## Findings:" >> "$report_file"
  echo "- Add findings here." >> "$report_file"
  echo "Report created: $report_file"
}

function zonetrans() {
  echo "Checking zone transfer for: $1"
  {dig +short "$1" NS | xargs -I{} dig +nocmd +noall +answer @{} "$1" axfr \
    | grep -v "; Transfer failed." | grep -E 'CNAME|A|AAAA';
  }
}


function mirror_website_normal (){
  echo "downloading the ${$1} website avaiable files"
  wget --random-wait -r -p -e robots=off -U mozilla $1
}

# mirror a website aggresivelly
# for largse fucntion we can do autoloading but this is not yet
# neccassary !
function mirror_website_agr(){
  [[ -z $1 ]] && {echo "Usage: $0 example.com"; return 3}
  echo mirroring target: $1

  {wget \
    --mirror --convert-links --adjust-extension --page-requisites --no-parent --random-wait --wait=0.1 --limit-rate=0 -e robots=off \
    -U "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36" \
    --no-check-certificate --retry-on-http-error=403,404,429,500,502,503,504 \
    --tries=100 --timeout=30 --span-hosts --include-directories="/*" --reject="" \
    --no-http-keep-alive --no-cache --no-cookies \
    --header="Accept: */*" \
    --header="Accept-Language: en-US,en;q=0.9" \
    --header="DNT: 1" \
    --restrict-file-names=windows \
    --user-agent="Mozilla/5.0" \
    --proxy-user="user:pass" \
    --execute robots=off \
    --recursive --level=inf \
    --domains=$1,*.$1 \
    --follow-tags=a,area,frame,iframe,link \
    $1 || echo failed; return 1;
  }
  echo Done; return 0
}

function urlencode() {
  local string="${1}"
  local strlen=${#string}
  local encoded=""
  local pos c o

  for (( pos=0 ; pos<strlen ; pos++ )); do
    c=${string:$pos:1}
    case "$c" in
      [-_.~a-zA-Z0-9] ) o="${c}" ;;
      * ) printf -v o '%%%02x' "'$c"
    esac
    encoded+="${o}"
  done
  echo "${encoded}"
}

function extract_http_dorks() {
  [[ -z $1 ]] && { echo "Usage: $0 \"dork\" [pages]" >&2; return 3 }
  local max_pages="${2:-1}"  # Default: 1 page
  local start_value=0
  local query=${1// /+}

  for ((page=1; page <= max_pages; page++)); do
    local url="https://www.google.com/search?q=${query}&start=${start_value}"
    sleep $(awk -v min=1 -v max=3 'BEGIN{srand(); print min+rand()*(max-min)}')
    {lynx --dump --nonumbers --accept_all_cookies "$url" \
      | grep "http" | cut -d "" -f2 | grep -o "http[^&]*"
    } | grep -oE "url\?.=[^&]+" | grep -v "google"| sed 's|^.*url?q=||'

    ((start_value+=10))
    [[ $start_value -ge 1000 ]] && break
  done
}

